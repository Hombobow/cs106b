Q1. Use the above encoding tree to decode the bit sequence `0101100011`.
A1.

MOONS

Q2. Prepare a table for the above encoding tree that lists each character with its assigned bit sequence.
Use your table to encode the string `"SONS"`.
A2.

character       N       M       S       O
bit sequence    00      010     011     1

SONS corresponds to the sequence 011100011

Q3. Huffman codes obey the _prefix_ property: no character's encoded bit sequence is a prefix of any other.
What feature of an encoding tree demonstrates that it obeys the prefix property?
A3.

Because the encoding tree uses leaves as the characters it ensures that no character is the parent of another character, hence no character is a prefix of another character.

Q4. Flatten the encoding tree above on the right into its sequence of bits (tree shape) and sequence of characters (tree leaves).
A4.

1101000
NMSO

Q5. Unflatten the sequences `110100100` (tree shape) and `FLERA` (tree leaves) to reconstruct the original encoding tree.
A5.
                *
            /       \
           *         *
          / \       / \
         F   *     R   A
            / \
           L   E

Q6. Construct a Huffman coding tree for the input `"BOOKKEEPER"`.
A6.

                    *
                /       \
               *         *
              / \       / \
             O   K     *   E
                      / \
                     R   *
                        / \
                       B   P

Q7. Calculate the entropy of your Huffman tree for `"BOOKKEEPER"`.
Confirm that if you had chosen to break ties in a different manner when constructing the tree,
this alternate tree has the same entropy as the optimal result.
A7.

My first tree was based on breaking ties by placing the larger tree first

The entropy of my first Huffman tree for "BOOKKEEPER" is based on the table of number of occurences, encoding length --> letter
number of occurences, encoding length   1, 4    1, 4    1, 3    2, 2    2, 2    3, 2
letter                                  B       P       R       O       K       E

entropy = (1*4 + 1*4 + 1*3 + 2*2 + 2*2 + 3*2) / 10 = 2.5

If I had instead broke ties by placing the larger tree last I would've gotten a tree that looks like:

                    *
                /       \
               *         *
              / \       / \
             K   *     E   *
                / \       / \
               B   P     R   O

The entropy of my second Huffman tree for "BOOKKEEPER" is based on the table of number of occurences, encoding length --> letter
number of occurences, encoding length   1, 3    1, 3    1, 3    2, 3    2, 2    3, 2
letter                                  B       P       R       O       K       E

entropy = (1*3 + 1*3 + 1*3 + 2*3 + 2*2 + 3*2) / 10 = 2.5

Q8. Consider the space of inputs of length 1000 that consists of varied occurrences of 100 distinct characters.
Of those various inputs, contrast which inputs result in a balanced Huffman tree versus those that produce a
very lopsided Huffman tree. As an example, what if each of the 100 characters were represented 10 times
(for a total of 1000 characters)? What would the Huffman tree look like?
What if, instead, 99 of the characters was represented only once, but the remaining character was represented 901 times (again, for a total of 1000 characters)? What would the Huffman tree look like?
Which of the two Huffman trees achieves more significant compression?
What does this tell you about what makes for a "good" versus "bad" Huffman tree?
A8.

This shows me that a good Huffman tree is made when the distribution is more skewed as in the case with 99 characters were represented only once and the other characters were represented 901 times
because in that case the less common words would be lower down the tree while the word that appears 901 times would be be represented by only one bit which nicely compresses the frequently used word.
A bad Huffman tree is made when the frequencies are roughly equal and each character represents roughly equal path lengths because very little compression is done.

Q9:
Which AI model did you choose (if you used multiple models, include all of them)
A9.

I only used GPT5.

Q10:
> What initial prompt did you use for the model (or models)? Paste the model’s response without the code it may or may not have produced.
A10.

Initial Prompt:
I am currently working on an assignment for Stanford's CS106B class.

Please help me write a functional jpegDecoder

My instructions are the following:

[For this part of the assignment, we would like you to use an LLM from the Stanford AI Playground to try and write a JPEG decoder based on your own Huffman code

Your code must use C++ without any additional libraries, and your own Huffman code must be integrated into the solution. Additionally, your code cannot use the Stanford Library’s GImage class or the Qt library’s QImage class.

Your code should be put into the jpegDecoder.cpp file, and you will need to start with the void loadJpeg(GCanvas& img, string filename) function, which should read a .jpg or .jpeg file and converts it into a Stanford Library GCanvas object, img, which has been passed in by reference.

Your code can use any helper functions, or even create one or more C++ classes. There isn’t any defined limit to the amount of code you have the AI produce.

Your code must use your code from huffman.cpp in some useful way.]

Currently my jpegDecoder.cpp file looks like this:

#include<iostream>
#include "grid.h"
#include "gcanvas.h"
#include "huffman.h"

using namespace std;

void loadJpeg(GCanvas& img, string filename) {
    // Your Code Here
    // GImage gim(filename);
    // Grid<int>grid(gim.getHeight(), gim.getWidth());
    // for (int r = 0; r < grid.numRows(); r++) {
    //     for (int c = 0; c < grid.numCols(); c++) {
    //         grid[r][c] = gim.getPixel(c, r);
    //     }
    // }
    Grid<int> grid;
    img.fromGrid(grid);
}

My own huffman.cpp file has the following Huffman decompression code:

/**
 * Given a Queue<Bit> containing the compressed message bits and the encoding tree
 * used to encode those bits, decode the bits back to the original message text.
 *
 * You can assume that tree is a well-formed non-empty encoding tree and
 * messageBits queue contains a valid sequence of encoded bits.
 *
 * Your implementation may change the messageBits queue however you like. There
 * are no requirements about what it should look like after this function
 * returns. The encoding tree should be unchanged.
 *
 * Iterates over the messageBits decoding character by character.
 */
string decodeText(EncodingTreeNode* tree, Queue<Bit>& messageBits) {
    //declare a string to store the decodedText
    string decodedText = "";

    //dequeue until messageBits is out of bits
    while(!messageBits.isEmpty()) {
        //start at the top of the tree
        EncodingTreeNode* node = tree;

        //traverse the tree until we find a character
        while (!node->isLeaf()) {
            if (messageBits.dequeue() == 0) {
                node = node->zero;
            } else {
                node = node->one;
            }
        }

        //append the leaf to the decoded text
        decodedText += node->getChar();
    }

    return decodedText;
}

/**
 * Reconstruct encoding tree from flattened form Queue<Bit> and Queue<char>.
 *
 * You can assume that the queues are well-formed and represent
 * a valid encoding tree.
 *
 * Your implementation may change the queue parameters however you like. There
 * are no requirements about what they should look like after this function
 * returns.
 *
 * Uses depth first recursion to reconstruct the full tree with the base case
 * being when we reach a leaf.
 */
EncodingTreeNode* unflattenTree(Queue<Bit>& treeShape, Queue<char>& treeLeaves) {
    //base case
    if (treeShape.dequeue() == 0) {
        //return a leaf node with the next dequeued character from treeLeaves
        return new EncodingTreeNode(treeLeaves.dequeue());
    }

    //recursive case
    EncodingTreeNode* left = unflattenTree(treeShape, treeLeaves);
    EncodingTreeNode* right = unflattenTree(treeShape, treeLeaves);

    //return the combination of the left and right subtrees
    return new EncodingTreeNode(left, right);
}

/**
 * Decompress the given EncodedData and return the original text.
 *
 * You can assume the input data is well-formed and was created by a correct
 * implementation of compress.
 *
 * Your implementation may change the data parameter however you like. There
 * are no requirements about what it should look like after this function
 * returns.
 *
 * Uses both the unflattenTree function and the decode text function to fully decode
 * an encoded piece of data given through EncodedData.
 */
string decompress(EncodedData& data) {
    //create the encoding tree using the unflattenTree function
    EncodingTreeNode* tree = unflattenTree(data.treeShape, data.treeLeaves);

    //store the decoded text in a string using the decodeText function
    string decodedText = decodeText(tree, data.messageBits);

    //deallocate the memory of the tree
    deallocateTree(tree);

    return decodedText;
}

The bits.h and bits.cpp look like this:

#pragma once
#include <ostream>
#include "queue.h"

/**
 * Type representing a single bit value (0 or 1).  A Bit is largely
 * interchangeable with an int, except that a Bit raises an error
 * if value is anything other than 0 or 1.
 *
 *     Bit zero = 0;
 *
 *     queue.enqueue(0);
 *     queue.enqueue(Bit(1));
 *
 *     if (bit == 0) { ... }
 */
class Bit {
public:
    Bit() = default;
    Bit(int value);

    friend bool operator== (Bit lhs, Bit rhs);
    friend bool operator!= (Bit lhs, Bit rhs);
    friend std::ostream& operator<< (std::ostream& out, Bit bit);

private:
    bool _value;
};



/*
 * Type representing a binary-encoded message. The messageBits contains
 * the encoded message text and the treeShape and treeLeaves are the
 * flattened representation of the encoding tree.
 */
struct EncodedData {
    Queue<Bit>  treeShape;
    Queue<char> treeLeaves;
    Queue<Bit>  messageBits;
};


/* For debugging purposes, you can print EncodedData objects to cout to see
 * what they contain.
 */
std::ostream& operator<< (std::ostream& out, const EncodedData& data);



/**
 * Routines for reading and writing EncodedData objects to a stream. The code in
 * here is what actually touches files on disk.
 */
void writeData(EncodedData& file, std::ostream& out);
EncodedData readData(std::istream& in);

#include "bits.h"
#include "error.h"
#include <string>
#include <vector>
using namespace std;

/**
 * Routines for managing Bit class and for reading/write Bits within EncodedData
 * objects to a stream.  The public interface is provided in bits.h header file.
 * You do not need to revew the implementation details in this file but are welcome
 * to take a peek if you're curious.
 */

Bit::Bit(int value) {
    /* Check for use of chararacter values. */
    if (value == '0' || value == '1') {
        error("You have attempted to create a bit equal to the character '0' or '1'. "
              "The characters '0' and '1' are not the same as the numbers 0 and 1. "
              "Edit your code to instead use the numeric values 0 and 1 instead.");
    }
    if (value != 0 && value != 1) {
        error("Illegal value for a bit: " + to_string(value));
    }

    _value = (value == 1);
}

bool operator== (Bit lhs, Bit rhs) {
    return lhs._value == rhs._value;
}
bool operator!= (Bit lhs, Bit rhs) {
    return !(lhs == rhs);
}
ostream& operator<< (ostream& out, Bit bit) {
    return out << (bit._value? '1' : '0');
}


namespace {
    /**
     * Validates that the given EncodedData obeys all the invariants we expect it to.
     */
    void checkIntegrityOf(const EncodedData& data) {
        /* Number of distinct characters must be at least two. */
        if (data.treeLeaves.size() < 2) {
            error("File must contain at least two distinct characters.");
        }

        /* Number of bits in tree shape should be exactly 2c - 1, where c is the number of
         * distinct characters.
         */
        if (data.treeShape.size() != data.treeLeaves.size() * 2 - 1) {
            error("Wrong number of tree bits for the given leaves.");
        }
    }

    /* Utility types for reading/writing individual bits. Inspired by a
     * similar implementation by Julie Zelenski.
     */
    class BitWriter {
    public:
        explicit BitWriter(ostream& o) : _out(o) {}
        ~BitWriter() {
            if (_bitIndex != 0) flush();
        }

        void put(Bit b) {
            if (b != 0) {
                _bitBuffer |= (1U << _bitIndex);
            }

            _bitIndex++;
            if (_bitIndex == 8) {
                flush();
            }
        }

    private:
        void flush() {
            _out.put(_bitBuffer);
            _bitBuffer = 0;
            _bitIndex = 0;
        }

        ostream& _out;
        uint8_t _bitBuffer = 0;
        uint8_t _bitIndex  = 0;
    };

    class BitReader {
    public:
        explicit BitReader(istream& i) : _in(i) {}

        Bit get() {
            if (_bitIndex == 8) readMore();

            Bit result = !!(_bitBuffer & (1U << _bitIndex));
            _bitIndex++;
            return result;
        }

    private:
        istream& _in;
        uint8_t _bitBuffer = 0;
        uint8_t _bitIndex  = 8;

        void readMore() {
            char read;
            if (!_in.get(read)) {
                error("Unexpected end of file when reading bits.");
            }

            _bitBuffer = read;
            _bitIndex = 0;
        }
    };

    /* "CS106B A7" */
    const uint32_t kFileHeader = 0xC5106BA7;
}

/**
 * We store EncodedData on disk as follows:
 *
 *
 * 1 byte:  number of distinct characters, minus one.
 * c bytes: the leaves of the tree, in order.
 * 1 byte:  number of valid bits in the last byte.
 * n bits:  tree bits, followed by message bits.
 *
 * We don't need to store how many bits are in the tree, since it's always given
 * by 2*c - 1, as this is the number of nodes in a full binary tree with c leaves.
 */
void writeData(EncodedData& data, ostream& out) {
    /* Validate invariants. */
    checkIntegrityOf(data);

    /* Write magic header. */
    out.write(reinterpret_cast<const char *>(&kFileHeader), sizeof kFileHeader);

    /* Number of characters. */
    const uint8_t charByte = data.treeLeaves.size() - 1;
    out.put(charByte);

    /* Tree leaves. */
    while (!data.treeLeaves.isEmpty()) out.put(data.treeLeaves.dequeue());

    /* Number of bits in the last byte to read. */
    uint8_t modulus = (data.treeShape.size() + data.messageBits.size()) % 8;
    if (modulus == 0) modulus = 8;
    out.put(modulus);

    /* Bits themselves. */
    BitWriter writer(out);
    while (!data.treeShape.isEmpty()) writer.put(data.treeShape.dequeue());
    while (!data.messageBits.isEmpty()) writer.put(data.messageBits.dequeue());
}

/**
 * Reads EncodedData from stream.
 */
EncodedData readData(istream& in) {
    /* Read back the magic header and make sure it matches. */
    uint32_t header;
    if (!in.read(reinterpret_cast<char *>(&header), sizeof header) ||
        header != kFileHeader) {
        error("Chosen file is not a Huffman-compressed file.");
    }

    EncodedData data;

    /* Read the character count. */
    char skewCharCount;
    if (!in.get(skewCharCount)) {
        error("Error reading character count.");
    }

    /* We offset this by one - add the one back. */
    int charCount = uint8_t(skewCharCount);
    charCount++;

    if (charCount < 2) {
        error("Character count is too low for this to be a valid file.");
    }

    /* Read in the leaves. */
    vector<char> leaves(charCount);
    if (!in.read(leaves.data(), leaves.size())) {
        error("Could not read in all tree leaves.");
    }
    for (char leaf: leaves) {
        data.treeLeaves.enqueue(leaf);
    }

    /* Read in the modulus. */
    char signedModulus;
    if (!in.get(signedModulus)) {
        error("Error reading modulus.");
    }
    uint8_t modulus = signedModulus;

    /* See how many bits we need to read. To do this, jump to the end of the file
     * and back to where we are to count the bytes, then transform that to a number
     * of bits.
     *
     * Thanks to Julie Zelenski for coming up with this technique!
     */
    auto currPos = in.tellg();
    if (!in.seekg(0, istream::end)) {
        error("Error seeking to end of file.");
    }
    auto endPos  = in.tellg();
    if (!in.seekg(currPos, istream::beg)) {
        error("Error seeking back to middle of file.");
    }

    /* Number of bits to read = (#bytes - 1) * 8 + modulus. */
    uint64_t bitsToRead = (endPos - currPos - 1) * 8 + modulus;

    /* Read in the tree shape bits. */
    BitReader reader(in);
    for (int i = 0; i < 2 * charCount - 1; i++) {
        data.treeShape.enqueue(reader.get());
        bitsToRead--;
    }

    /* Read in the message bits. */
    while (bitsToRead > 0) {
        data.messageBits.enqueue(reader.get());
        bitsToRead--;
    }

    return data;
}

/* For debugging purposes. */
ostream& operator<< (ostream& out, const EncodedData& data) {
    ostringstream builder;
    builder << "{treeShape:" << data.treeShape
            << ",treeLeaves:" << data.treeLeaves
            << ",messageBits:" << data.messageBits
            << "}";
    return out << builder.str();
}

The header file for the GCanvas object:

/*
 * File: gcanvas.h
 * ---------------
 *
 * @author Marty Stepp
 * @version 2019/05/01
 * - added createArgbPixel
 * - bug fixes related to save / setPixels with alpha transparency
 * @version 2019/03/07
 * - added support for loading canvas directly from istream (htiek)
 * @version 2018/09/10
 * - added doc comments for new documentation generation
 * @version 2018/09/04
 * - added double-click event support
 * @version 2018/08/23
 * - renamed to gcanvas.h to replace Java version
 * @version 2018/06/30
 * - initial version
 */


#ifndef _gcanvas_h
#define _gcanvas_h

#include <string>
#include <QtEvents>
#include <QPainter>

#include "gdrawingsurface.h"
#include "gevent.h"
#include "ginteractor.h"
#include "gobjects.h"

// default color used to highlight pixels that do not match between two images
#define GCANVAS_DEFAULT_DIFF_PIXEL_COLOR 0xdd00dd

class _Internal_QCanvas;

/**
 * A GCanvas is a graphical drawing surface on which you can draw shapes, lines,
 * and colors, as well as setting the RGB color values of individual pixels.
 *
 * The graphical canvas consists of two layers:
 *
 * 1) The background layer provides a surface for drawing static pictures that
 * involve no animation, or for 2D pixel-based drawing algorithms.
 * The class includes several drawXxx and fillXxx methods that draw
 * lines, rectangles, and ovals on the background layer.
 *
 * The setPixel and setPixels methods manipulate the color of pixels in the
 * background layer.  You can get all of the pixels as a Grid using getPixels,
 * modify the grid, then pass it back in using setPixels, to perform 2D
 * pixel-based manipulations on the canvas.
 *
 * 2) The foreground layer provides an abstraction for adding stateful shapes and
 * graphical objects onto the canvas.  The add() methods that accept GObject
 * parameters place these objects onto the foreground layer.  The advantage of
 * the foreground layer is that you can manipulate the object over time, such as
 * moving it, changing its color, size, or other properties, and see these
 * changes immediately on the screen.  This makes the foreground layer most
 * appropriate for animations or moving sprites.
 *
 * A GCanvas is implicitly added to the center of every GWindow when the client
 * calls the window's add(), drawXxx/fillXxx, or other methods.  In most cases
 * the window just forwards these method calls to its internal GCanvas, which
 * performs the bulk of the work.
 *
 * See gobjects.h for more detail about drawing shapes and objects.
 */
class GCanvas : public virtual GInteractor, public virtual GDrawingSurface {
public:
    /**
     * Largest value that an image's width and/or height can have.
     * Error will be thrown if you try to make/resize an image larger than this.
     */
    static const int WIDTH_HEIGHT_MAX;

    /**
     * Creates a single ARGB integer from the given A-R-G-B components from 0-255.
     * @throw ErrorException if alpha, red, green, or blue is not between 0-255 inclusive
     */
    static int createArgbPixel(int alpha, int red, int green, int blue);

    /**
     * Creates a single RGB integer from the given R-G-B components from 0-255.
     * @throw ErrorException if red, green, or blue is not between 0-255 inclusive
     */
    static int createRgbPixel(int red, int green, int blue);

    /**
     * Extracts the alpha component from 0-255 of the given ARGB integer.
     * The alpha component comes from bits 24-31 (most significant) of the integer.
     */
    static int getAlpha(int argb);

    /**
     * Extracts the blue component from 0-255 of the given RGB integer.
     * The blue component comes from bits 0-7 (least significant) of the integer.
     */
    static int getBlue(int rgb);

    /**
     * Extracts the green component from 0-255 of the given RGB integer.
     * The green component comes from bits 8-15 of the integer.
     */
    static int getGreen(int rgb);

    /**
     * Extracts the red component from 0-255 of the given RGB integer.
     * The red component comes from bits 16-23 of the integer.
     */
    static int getRed(int rgb);

    /**
     * Extracts the red, green, and blue components from 0-255
     * of the given RGB integer, filling by reference.
     */
    static void getRedGreenBlue(int rgb, int& red, int& green, int& blue);

    /**
     * Creates an empty canvas with a default size of 0x0 pixels
     * and a default background and foreground color of black.
     */
    GCanvas(QWidget* parent = nullptr);

    /**
     * Creates a canvas that loads its background layer pixel data from
     * the given image file name.
     * @throw ErrorException if the given file does not exist or cannot be read
     *        as a valid image file
     */
    GCanvas(const std::string& filename, QWidget* parent = nullptr);

    /**
     * Creates a canvas that loads its background layer pixel data from
     * the given input stream
     * @throw ErrorException if the given stream cannot be read as a valid image file
     */
    GCanvas(std::istream& filename, QWidget* parent = nullptr);

    /**
     * Creates an empty canvas of the specified size and optional background color.
     * If no background color is passed, a default transparent background is used.
     * @throw ErrorException if the given width/height ranges are negative
     * @throw ErrorException if the given rgb value is invalid or out of range
     */
    GCanvas(double width, double height, int rgbBackground, QWidget* parent = nullptr);

    /**
     * Creates an empty canvas of the specified size and background color.
     * If no background color is passed, a default transparent background is used.
     * @throw ErrorException if the given width/height ranges are negative
     * @throw ErrorException if the given rgb value is invalid or out of range
     */
    GCanvas(double width, double height, const std::string& rgbBackground = "#00000000", QWidget* parent = nullptr);

    /**
     * Frees memory allocated internally by the canvas.
     */
    ~GCanvas() override;

    /**
     * Adds the given interactor to canvas.
     * @throw ErrorException if the interactor is null
     */
    virtual void add(GObject* gobj);

    /**
     * Adds the given interactor to the canvas
     * and moves it to the given x/y location.
     * @throw ErrorException if the interactor is null
     */
    virtual void add(GObject* gobj, double x, double y);

    /**
     * Adds the given interactor to canvas.
     */
    virtual void add(GObject& gobj);

    /**
     * Adds the given interactor to the canvas
     * and moves it to the given x/y location.
     */
    virtual void add(GObject& gobj, double x, double y);

    /**
     * Removes all graphical objects from the canvas foreground layer
     * and wipes the background layer to show the current background color.
     */
    void clear() override;

    /**
     * Removes all graphical objects from the foreground layer of the canvas.
     * This means that any shapes added using the add() methods, such as GRect,
     * GOval, etc. will be removed, while any shapes drawn directly onto the
     * canvas's background pixel layer by calling the drawXxx() methods will be
     * retained.  To clear the background layer as well, call clearPixels
     * or clear instead.
     */
    virtual void clearObjects();

    /**
     * Resets the background layer of pixels in the canvas to the current
     * background color.
     * This means that any shapes added using the add() methods, such as GRect,
     * GOval, etc. will remain, while any shapes drawn directly onto the
     * canvas's background pixel layer by calling the drawXxx() methods will be
     * wiped out.  To clear the shapes added to the foreground layer as well,
     * call clearObjects or clear instead.
     */
    virtual void clearPixels();

    /**
     * Returns true if any of the graphical objects in the foreground layer of
     * the canvas touch the given x/y pixel.
     */
    virtual bool contains(double x, double y) const;

    /**
     * Returns the total number of pixels that are not the same color
     * between this image and the given other image.
     * If the images are not the same size, any pixels in the range of one image
     * but out of the bounds of the other are considered to be differing.
     * In this version of the method, the entire images are compared.
     */
    virtual int countDiffPixels(const GCanvas& image) const;

    /**
     * Returns the total number of pixels that are not the same color
     * between this image and the given other image.
     * If the images are not the same size, any pixels in the range of one image
     * but out of the bounds of the other are considered to be differing.
     * In this version of the method, you pass an (x,y) range of pixels to compare.
     */
    virtual int countDiffPixels(const GCanvas& image, int xmin, int ymin, int xmax, int ymax) const;

    /**
     * Returns the total number of pixels that are not the same color
     * between this image and the given other image.
     * If the images are not the same size, any pixels in the range of one image
     * but out of the bounds of the other are considered to be differing.
     * In this version of the method, the entire images are compared.
     * @throw ErrorException if the image passed is null
     */
    virtual int countDiffPixels(const GCanvas* image) const;

    /**
     * Returns the total number of pixels that are not the same color
     * between this image and the given other image.
     * If the images are not the same size, any pixels in the range of one image
     * but out of the bounds of the other are considered to be differing.
     * In this version of the method, you pass an (x,y) range of pixels to compare.
     * @throw ErrorException if the image passed is null
     */
    virtual int countDiffPixels(const GCanvas* image, int xmin, int ymin, int xmax, int ymax) const;

    /**
     * Generates a new canvas whose content is equal to that of this canvas but with
     * any pixels that don't match those in parameter 'image' colored in the given
     * color (default purple) to highlight differences between the two.
     */
    virtual GCanvas* diff(const GCanvas& image, int diffPixelColor = GCANVAS_DEFAULT_DIFF_PIXEL_COLOR) const;

    /**
     * Generates a new canvas whose content is equal to that of this canvas but with
     * any pixels that don't match those in parameter 'image' colored in the given
     * color (default purple) to highlight differences between the two.
     * @throw ErrorException if the image passed is null
     */
    virtual GCanvas* diff(const GCanvas* image, int diffPixelColor = GCANVAS_DEFAULT_DIFF_PIXEL_COLOR) const;

    /**
     * Draws the given graphical object onto the background layer of the canvas.
     * Note that since it is drawn on the background layer, future changes to
     * the graphical object, such as setting its location, color, size, etc.,
     * will not be reflected immediately on this canvas.
     * If you do want such changes to be reflected, instead add the shape to
     * the foreground layer using add().
     * @throw ErrorException if the object passed is null
     */
    void draw(GObject* gobj) override;

    /**
     * @inherit
     * @private
     */
    void draw(QPainter* painter) override;

    /**
     * Returns true if the two given canvases contain exactly the same pixel data.
     */
    virtual bool equals(const GCanvas& other) const;

    /**
     * Sets the color of every pixel in the canvas to the given color value.
     * See gcolor.h for more detail about colors.
     * @throw ErrorException if the given rgb value is not a valid color
     */
    virtual void fill(int rgb);

    /**
     * Sets the color of every pixel in the canvas to the given color value.
     * See gcolor.h for more detail about colors.
     */
    virtual void fill(const std::string& rgb);

    /**
     * Sets the color of every pixel in the given rectangular range of the canvas
     * pixel data to the given color value.
     * Specifically, the pixels in the rectangular range (x, y) through
     * (x + width - 1, y + height - 1) become filled with the given color.
     * @throw ErrorException if the given x/y/width/height range goes outside
     *        the bounds of the image,
     *        or if the given rgb value is not a valid color
     */
    virtual void fillRegion(double x, double y, double width, double height, int rgb);

    /**
     * Sets the color of every pixel in the given rectangular range of the canvas
     * pixel data to the given color value.
     * Specifically, the pixels in the rectangular range (x, y) through
     * (x + width - 1, y + height - 1) become filled with the given color.
     * @throw ErrorException if the given x/y/width/height range goes outside
     *        the bounds of the image
     */
    virtual void fillRegion(double x, double y, double width, double height,
                            const std::string& rgb);

    /**
     * Moves all graphical objects from the foreground layer to the background
     * layer.  This means that future changes to those objects will not be
     * seen on the canvas.
     */
    virtual void flatten();

    /**
     * Replaces the entire contents of the background layer of the canvas with
     * the contents of the given grid of RGB pixel values.
     * If this image is not the same size as the grid, the image is resized.
     * Any previous background layer contents are lost.
     * Equivalent to getPixels.
     */
    virtual void fromGrid(const Grid<int>& grid);

    /* @inherit */
    std::string getBackground() const override;

    /* @inherit */
    int getBackgroundInt() const override;

    /**
     * Returns a pointer to the graphical object in the foreground layer of
     * the canvas at the specified index, numbering from back to front in the
     * <i>z</i> dimension.
     * @throw ErrorException if the index is out of range
     */
    virtual GObject* getElement(int index) const;

    /**
     * Returns a pointer to the first graphical object in the foreground layer of
     * the canvas that contains the given (x, y) point, or a null pointer if no
     * object in this canvas touches it.
     */
    virtual GObject* getElementAt(double x, double y) const;

    /**
     * Returns the number of graphical objects stored in the foreground layer
     * of the canvas.
     */
    virtual int getElementCount() const;

    /**
     * Returns the name of the image file from which this canvas was loaded or
     * to which it was saved most recently.
     * If this canvas was not associated with any file, returns "".
     */
    virtual std::string getFilename() const;

    /* @inherit */
    std::string getFont() const override;

    /* @inherit */
    _Internal_QWidget* getInternalWidget() const override;

    /**
     * Returns the color of the pixel at the given x/y coordinates of the
     * background layer of the canvas as an integer such as 0xff00cc.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixels to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixels to submit all of your changes.
     *
     * @throw ErrorException if the given x/y values are out of bounds.
     */
    int getPixel(double x, double y) const override;

    /**
     * Returns the color of the pixel at the given x/y coordinates of the
     * background layer of the canvas as an integer such as 0xffff00cc.
     * This differs from getPixel in that it explicitly retains and returns
     * the alpha channel of the pixel in the top 8 bits, allowing for
     * transparency effects.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixels to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixels to submit all of your changes.
     *
     * @throw ErrorException if the given x/y values are out of bounds.
     */
    int getPixelARGB(double x, double y) const override;

    /**
     * Returns all pixels of the background layer of the canvas as a Grid,
     * where rows represent y values and columns represent x values.
     * So for example, grid[y][x] returns the RGB int value at that pixel.
     * Equivalent to toGrid.
     */
    Grid<int> getPixels() const override;

    /**
     * Returns all pixels of the background layer of the canvas as a Grid,
     * where rows represent y values and columns represent x values.
     * This differs from getPixels in that it explicitly retains and returns
     * the alpha channel of each pixel in the top 8 bits, allowing for
     * transparency effects.
     */
    Grid<int> getPixelsARGB() const override;

    /* @inherit */
    std::string getType() const override;

    /* @inherit */
    QWidget* getWidget() const override;

    /* @inherit */
    bool isAutoRepaint() const override;

    /**
     * Reads the canvas's pixel contents from the given image file.
     * @throw ErrorException if the given file does not exist or cannot be read
     *        as a valid image file
     */
    virtual void load(const std::string& filename);

    /**
     * Reads the canvas's pixel contents from the given input stream.
     * @throw ErrorException if the given file does not exist or cannot be read
     *        as a valid image file
     */

    /**
     * Removes the given graphical object from the foreground layer of the canvas,
     * if it was present.
     * @throw ErrorException if the graphical object is null
     */
    virtual void remove(GObject* gobj);

    /**
     * Removes the given graphical object from the foreground layer of the canvas,
     * if it was present.
     */
    virtual void remove(GObject& gobj);

    /**
     * Removes all graphical objects from the foreground layer of the canvas.
     */
    virtual void removeAll();

    /**
     * Instructs the canvas to redraw its layers.
     * By default the canvas will automatically repaint itself whenever you make
     * a change to either the background or foreground layer.
     * But if you call setAutoRepaint(false), you must manually repaint the canvas
     * to see any changes. This can be desirable if you plan to make a large batch
     * of changes and want to repaint only after all of them are done.
     */
    void repaint() override;

    /**
     * Instructs the canvas to redraw the given region of pixels within both
     * of its layers.
     */
    void repaintRegion(int x, int y, int width, int height) override;

    /**
     * Changes this image's bounds to be the given size.
     * This does not scale the image but rather just changes the max x/y that
     * can be painted onto this image.
     * If the 'retain' parameter is not passed or is set to true,
     * any existing pixel values will be kept during the resize.
     * If 'retain' is false, the contents will be wiped and set to the default.
     * Any existing pixel contents are discarded and revert to defaults.
     * @throw ErrorException if the given width/height ranges are negative
     */
    void resize(double width, double height, bool retain = true);

    /**
     * Saves the canvas's contents to the given image file.
     * @throw ErrorException if the given file is not writeable.
     */
    virtual void save(const std::string& filename);

    /**
     * Sets whether the canvas will automatically repaint itself whenever you make
     * a change to either the background or foreground layer.
     * By default this is true.
     * But if you call setAutoRepaint(false), you must manually repaint the canvas
     * to see any changes. This can be desirable if you plan to make a large batch
     * of changes and want to repaint only after all of them are done.
     */
    void setAutoRepaint(bool autoRepaint) override;

    /* @inherit */
    void setBackground(int color) override;

    /* @inherit */
    void setBackground(const std::string& color) override;

    /* @inherit */
    void setColor(int color) override;

    /* @inherit */
    void setColor(const std::string& color) override;

    /* @inherit */
    void setFont(const QFont& font) override;

    /* @inherit */
    void setFont(const std::string& font) override;

    /* @inherit */
    void setForeground(int rgb) override;

    /* @inherit */
    void setForeground(const std::string& color) override;

    /**
     * Sets a key listener on this canvas so that it will be called
     * when any key is pressed or released on the canvas.
     * Any existing key listener will be replaced.
     */
    void setKeyListener(GEventListener func) override;

    /**
     * Sets a key listener on this canvas so that it will be called
     * when any key is pressed or released on the canvas.
     * Any existing key listener will be replaced.
     */
    void setKeyListener(GEventListenerVoid func) override;

    /**
     * Sets the color of the given x/y pixel in the background layer of the
     * canvas to the given RGB value.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixels to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixels to submit all of your changes.
     *
     * @throw ErrorException if x/y is out of range or rgb is an invalid color
     */
    void setPixel(double x, double y, int rgb) override;

    /**
     * Sets the color of the given x/y pixel in the background layer of the
     * canvas to the given RGB values.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixels to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixels to submit all of your changes.
     *
     * @throw ErrorException if x/y is out of range or r,g,b are not between 0-255
     */
    void setPixel(double x, double y, int r, int g, int b) override;

    /**
     * Sets the color of the given x/y pixel in the background layer of the
     * canvas to the given ARGB value.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixelsARGB to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixelsARGB to submit all of your changes.
     *
     * @throw ErrorException if x/y is out of range or argb is an invalid color
     */
    void setPixelARGB(double x, double y, int argb) override;

    /**
     * Sets the color of the given x/y pixel in the background layer of the
     * canvas to the given ARGB values.
     *
     * Note that if you are planning to set many pixels in the background and
     * want maximum performance, you should instead call getPixelsARGB to extract
     * all pixels into a Grid, then manipulate all desired pixels in that Grid,
     * then call setPixelsARGB to submit all of your changes.
     *
     * @throw ErrorException if x/y is out of range or a,r,g,b are not between 0-255
     */
    void setPixelARGB(double x, double y, int a, int r, int g, int b) override;

    /**
     * Sets the color of the all pixels in the background layer of the
     * canvas to the given RGB values, using rows as y-values and columns as
     * x-values.  Any existing background layer pixels will be replaced.
     * If the given grid is not the same size as this canvas, the canvas will
     * be resized to match the grid.
     * Equivalent to fromGrid.
     */
    void setPixels(const Grid<int>& pixels) override;

    /**
     * Sets the color of the all pixels in the background layer of the
     * canvas to the given ARGB values, using rows as y-values and columns as
     * x-values.  Any existing background layer pixels will be replaced.
     * If the given grid is not the same size as this canvas, the canvas will
     * be resized to match the grid.
     */
    void setPixelsARGB(const Grid<int>& pixelsARGB) override;

    /**
     * Converts the pixels of the canvas into a GImage object.
     */
    virtual GImage* toGImage() const;

    /**
     * Converts this canvas's pixel data into a grid of RGB pixels.
     * The grid's first index is a row or y-index, and its second index
     * is the column or x-index.
     * So for example, grid[y][x] returns the RGB int value at that pixel.
     * In this version of the method, the grid is returned.
     * Equivalent to getPixels.
     */
    virtual Grid<int> toGrid() const;

    /**
     * Converts this canvas's pixel data into a grid of RGB pixels.
     * The grid's first index is a row or y-index, and its second index
     * is the column or x-index.
     * So for example, grid[y][x] returns the RGB int value at that pixel.
     * In this version of the method, the grid is filled by reference.
     * Equivalent to getPixels.
     */
    virtual void toGrid(Grid<int>& grid) const;

private:
    Q_DISABLE_COPY(GCanvas)

    _Internal_QCanvas* _iqcanvas;
    GCompound _gcompound;
    QImage* _backgroundImage;
    std::string _filename;   // file canvas was loaded from; "" if not loaded from a file

    friend class _Internal_QCanvas;

    void ensureBackgroundImage();

    void ensureBackgroundImageConstHack() const;

    void init(double width, double height, int rgbBackground, QWidget* parent);

    /**
     * Reads the canvas's pixel contents from the given stream.
     * @return true if loaded successfully and false if the load failed
     */
    virtual bool loadFromStream(std::istream& input);

    void notifyOfResize(double width, double height);
};

// Parameter has new type >= Qt 6
#if QT_VERSION < QT_VERSION_CHECK(6, 0, 0)
    typedef QEvent ParameterToEnterEvent;
#else
    typedef QEnterEvent ParameterToEnterEvent;
#endif

/**
 * Internal class; not to be used by clients.
 * @private
 */
class _Internal_QCanvas : public QWidget, public _Internal_QWidget {
    Q_OBJECT

public:
    _Internal_QCanvas(GCanvas* gcanvas, QWidget* parent = nullptr);
    void detach() override;
    void enterEvent(ParameterToEnterEvent* event) override;
    void keyPressEvent(QKeyEvent* event) override;
    void keyReleaseEvent(QKeyEvent* event) override;
    void leaveEvent(QEvent* event) override;
    void mouseMoveEvent(QMouseEvent* event) override;
    void mousePressEvent(QMouseEvent* event) override;
    void mouseReleaseEvent(QMouseEvent* event) override;
    void paintEvent(QPaintEvent *event) override;
    void resizeEvent(QResizeEvent* event) override;
    virtual void setCanvasSize(double width, double height);
    QSize sizeHint() const override;
    void wheelEvent(QWheelEvent* event) override;

signals:
    void doubleClicked();

protected:
    void mouseDoubleClickEvent(QMouseEvent* e) override;

private:
    GCanvas* _gcanvas;

    friend class GCanvas;
};

#endif // _gcanvas_h

GPT5's response:
Below is a self-contained jpegDecoder.cpp that implements a baseline JPEG decoder in C++ without using any external image libraries and without using GImage or QImage. It parses a subset of JPEGs: baseline (SOF0), single-scan (SOS), 8-bit precision, and with no chroma subsampling (4:4:4 only; all sampling factors must be 1). It builds Huffman decoding trees from the DHT segments and uses your Huffman infrastructure (EncodingTreeNode, deallocateTree, Bit, Queue<Bit>) to decode the entropy-coded data. After inverse quantization and inverse DCT, it converts YCbCr to RGB and populates the Stanford Grid<int> for use with GCanvas::fromGrid.

Notes and limitations:

Supports only baseline JPEG (SOF0) with one scan (SOS) and no subsampling (all components must have H=V=1). Most phone/camera JPEGs use 4:2:0 subsampling, which this code will reject; test with simple baseline 4:4:4 images.
Ignores restart markers and multiple scans.
Uses a straightforward, but slower, floating-point IDCT; fine for small images in assignments.
Uses your Huffman node type and queues. It builds a canonical Huffman tree from the JPEG DHT codes, then decodes symbols using an adapted traversal that matches the logic of your decodeText.
Place this code into jpegDecoder.cpp to replace your stub.

<code produced>

This code:

Opens the JPEG file and verifies SOI.
Parses DQT, DHT, SOF0, and SOS markers.
Builds canonical Huffman trees from DHT using a temporary tree, then converts to your EncodingTreeNode type.
Reads entropy-coded data with proper byte-stuffing handling (0xFF 0x00).
Uses a Queue<Bit> of your Bit type for decoding and a decodeOneSymbol function that matches your decodeText traversal strategy but stops at a single symbol.
Decodes MCUs assuming 4:4:4, performs inverse quantization and an 8x8 floating-point IDCT.
Converts YCbCr to RGB and writes into a Grid<int>, then loads it into the GCanvas via fromGrid.
This integrates your Huffman code by using the EncodingTreeNode structure and deallocateTree, and by decoding the bitstream via a traversal akin to your decodeText logic.


Q11:
> Were you able to integrate the model’s code responses into your own code and get it to compile successfully?
A11.

I was able to prompt GPT5 to give me a jpegDecoder.cpp file that compiles successfully!
Although the code was so lengthy that I wasn't able to understand much of it.

Q12:
> If you needed to fix bugs, what was your process? What was easy/hard about that process? Did you simply ask the model to fix its errors, or did you attempt to fix them in the code yourself?
A12.

I had to fix one bug where the stanford library said that (Only H=1, V=1 (4:4:4) sampling supported.).
I wasn't able to understand what the bug meant but I ran the debugger and it traced to a piece of code I didn't understand at all so I just asked the model to help me fix the error which ended up getting me a working piece of code.
I also attempted to fix a second issue since the decoder was not properly displaying the cat.jpeg image and it gave pixelated images for the rest of them.
It wasn't a compile error and I had no idea where the issue was so I couldn't figure it out.

Q13:
> What, if anything, was frustrating about the process?
A13.

I feel like not understanding any of the code the was written was frustrating and completely relying on the model felt like I wasn't learning anything.
I felt that if at any point the code stopped working I would be completely reliant on the model to fix it as I didn't even have a slight idea of what any of the functions did.

Q14:
> Does your program successfully decode jpeg images with the code that the AI / you produced? If so, how long did it take? If not, how long did you spend, and what made you finally give up trying? 
A14.

I am not 100% sure if my program is successfully decoding the jpeg images as it still looks a bit pixelated however it didn't take too long to get a piece of code that compiles.
It took me around one and a half hours and I think my code partially works, but the cat.jpeg file still doesn't load and the rest of the images are a bit pixelated.
I feel like not being able to comprehend the error made me give up trying.

Q15:
> Please reflect on which of the prompts that you used generated the most useful responses, and reflect on if there was anything specific that you included that might have helped get good responses.
A15.

I believe the initial prompt where I gave the AI Model the full context generated me the most useful response as that laid the ground work for the rest of the code.
If I had begun with more faulty code I believe it may have been exponentially more difficult to complete the assignment.

Please paste all of your prompts (not the responses) below. You can leave out your own code or the code for the Stanford libraries (just replace with <code here>)

Prompt 1:
I am currently working on an assignment for Stanford's CS106B class.

Please help me write a functional jpegDecoder

My instructions are the following:

[For this part of the assignment, we would like you to use an LLM from the Stanford AI Playground to try and write a JPEG decoder based on your own Huffman code

Your code must use C++ without any additional libraries, and your own Huffman code must be integrated into the solution. Additionally, your code cannot use the Stanford Library’s GImage class or the Qt library’s QImage class.

Your code should be put into the jpegDecoder.cpp file, and you will need to start with the void loadJpeg(GCanvas& img, string filename) function, which should read a .jpg or .jpeg file and converts it into a Stanford Library GCanvas object, img, which has been passed in by reference.

Your code can use any helper functions, or even create one or more C++ classes. There isn’t any defined limit to the amount of code you have the AI produce.

Your code must use your code from huffman.cpp in some useful way.]

Currently my jpegDecoder.cpp file looks like this:

<code here>

My own huffman.cpp file has the following Huffman decompression code:

<code here>

The bits.h and bits.cpp look like this:

<code here>

The header file for the GCanvas object:

<code here>

Prompt 2:
The code provided had code from go, scss, and python.
The CS106B class primarly uses c++ code based on the stanford library.
Can you rewrite the code I will paste into jpegDecoder.cpp in only c++

Prompt 3:
Here is code for a JPEG decoder written using the Stanford C++ library and a pre-written Huffman Decoding algorithm. It has the following bug:

*** STANFORD C++ LIBRARY
*** The Huffman program has terminated unexpectedly (crashed)
*** A fatal error was reported:

    Only H=1, V=1 (4:4:4) sampling supported.

*** To get more information about a program crash,
*** run your program again under the debugger.

Please help fix that bug so that the JPEG decoder works properly. You must not use any external libraries other than the Stanford Library, and you may not use the GImage class or the QImage Qt class.

My instructions are the following:

[For this part of the assignment, we would like you to use an LLM from the Stanford AI Playground to try and write a JPEG decoder based on your own Huffman code

Your code must use C++ without any additional libraries, and your own Huffman code must be integrated into the solution. Additionally, your code cannot use the Stanford Library’s GImage class or the Qt library’s QImage class.

Your code should be put into the jpegDecoder.cpp file, and you will need to start with the void loadJpeg(GCanvas& img, string filename) function, which should read a .jpg or .jpeg file and converts it into a Stanford Library GCanvas object, img, which has been passed in by reference.

Your code can use any helper functions, or even create one or more C++ classes. There isn’t any defined limit to the amount of code you have the AI produce.

Your code must use your code from huffman.cpp in some useful way.]

<code here>

My huffman decoder code:

<code here>

Prompt 4:
could you rewrite the code without the extra explanations so I can copy paste into my file without worrying about the extra text

Prompt 5:
The following code worked thank you so much!

Prompt 6:
I was wondering if there was any way to make the decoding less pixelated as the current code compiles a really pixelated version of the jpeg and it is still crashing for the cat jpeg I inputted

Prompt 7:
I ran into the compile error use of [undeclared identifier 'findComponentIndexByld'] on lines 547, 586, 587 and 588

and the compile error [[jpegDecoder.o] Error 1]
